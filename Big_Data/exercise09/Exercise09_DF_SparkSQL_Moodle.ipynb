{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Big Data &ndash; Moodle Exercises </center>\n",
    "## <center>Fall 2024 &ndash; Week 9 &ndash; ETH Zurich</center>\n",
    "## <center>Spark Dataframes and Spark SQL, Moodle exercise</center>\n",
    "\n",
    "# Preparation for the moodle exercise in Spark\n",
    "\n",
    "In this jupyter notebook we are going to make the preprocessing part of the dataset that is going to be used in the graded exercise of this week. It will be the same language game dataset as seen in the exercises. If you still do not have created the `confusion-part.json` file, follow these instruction. If you only have it in the `exercise08` folder please copy the `confusion-2014-03-02` folder in the `notebooks` folder of your exam magic box.\n",
    "\n",
    "1. Move to the `notebooks` folder in the terminal\n",
    "2. Download the data: <br>\n",
    "   ```wget https://f003.backblazeb2.com/file/larsyencken-eu-public/greatlanguagegame/confusion-2014-03-02.tbz2``` <br>\n",
    "   __or__ <br>\n",
    "   ```curl -O https://f003.backblazeb2.com/file/larsyencken-eu-public/greatlanguagegame/confusion-2014-03-02.tbz2```\n",
    "3. Extract the data: <br>\n",
    "   ```tar -jxvf confusion-2014-03-02.tbz2```\n",
    "4. Change directory to ```confusion-2014-03-02```\n",
    "5. Extract the part of the dataset that we will work with in this exercise: <br>\n",
    "   ```head -n 3000000 confusion-2014-03-02.json > confusion-part.json```\n",
    "## More Info about the data\n",
    "You can find more information about the dataset (as well as the schema and examples) in the `README.md` file inside the data bundle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "In every query we ask you for three quantities: the query itself, the result of the query as well as the productivity time. That means the development time of each query (time elapsed from before you start writing the query, until the time at which the correct, final query is ready). Note that the time part of every question is optional and not graded. In order to make easier the time recording we created two functions that do it automatically. Run the cell below in order to import the functions into the current notebook. Then before each query we will have a ```start_exercise()``` cell that you have to run in order to start time recording. After you have finished your query and you are sure about the answer run the ```finish_exercise()``` one to get the time measurement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 39.236083984375,
      "end_time": 1573672504782.379
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def start_exercise():\n",
    "    global last\n",
    "    last = time.time()\n",
    "    \n",
    "def finish_exercise():\n",
    "    global last\n",
    "    print(\"This exercise took {0}s\".format(int(time.time()-last)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>1. Spark Dataframes</center>\n",
    "\n",
    "Write queries for the same dataset as last week, but this time using Spark Dataframes operations (the data loading will take a couple minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 11301.424072265625,
      "end_time": 1573676870300.81
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/20 16:30:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/20 16:30:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "path = \"confusion-2014-03-02/confusion-part.json\"\n",
    "dataset = spark.read.json(path).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 247.257080078125,
      "end_time": 1573676894196.787
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------+---------+--------------------+---------+\n",
      "|             choices|country|      date|    guess|              sample|   target|\n",
      "+--------------------+-------+----------+---------+--------------------+---------+\n",
      "|[Maori, Mandarin,...|     AU|2013-08-19|Norwegian|48f9c924e0d98c959...|Norwegian|\n",
      "|[Danish, Dinka, K...|     AU|2013-08-19|    Dinka|af5e8f27cef9e689a...|    Dinka|\n",
      "|[German, Hungaria...|     AU|2013-08-19|  Turkish|509c36eb58dbce009...|   Samoan|\n",
      "+--------------------+-------+----------+---------+--------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#test it out\n",
    "dataset.limit(3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "Find the number of games where one of the choices is Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 951.284912109375,
      "end_time": 1573677112003.169
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164496"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "dataset.filter(array_contains(\"choices\", \"Italian\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 306s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "Return the number of (distinct) countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 751.157958984375,
      "end_time": 1573677210603.419
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select(dataset.country).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 36s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "Return the sample IDs (i.e., the \"sample\" field) of the top 2 games played in Switzerland (CH) where the guessed language is correct (equal to the target one) ordered by date (ascending), then by language (descending)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 757.619140625,
      "end_time": 1573677388481.756
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|sample                          |\n",
      "+--------------------------------+\n",
      "|74b5340a230b1e0c1d45787bc4280b05|\n",
      "|b7df3f9d67cef259fbcaa5abcad9d774|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import asc, desc\n",
    "\n",
    "swiss_games = dataset.filter(dataset.country == 'CH')\n",
    "swiss_games.filter(swiss_games.guess == swiss_games.target).select(\"*\").orderBy(asc(\"date\"), desc(\"target\")).select(\"sample\").limit(2).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 281s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "Aggregate all games by guess and target language, ignoring games with correct guesses, count the number of guesses for each group and return the pair with the highest count i.e. the most confused pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 1262.1181640625,
      "end_time": 1573677845774.178
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+\n",
      "|   guess|   target|guesses|\n",
      "+--------+---------+-------+\n",
      "|Mandarin|Cantonese|    822|\n",
      "+--------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "bad_games = dataset.filter(dataset.target != dataset.guess).select(\"guess\", \"target\")\n",
    "bad_games.select(\"*\").groupBy(\"guess\", \"target\").agg(count(\"guess\").alias(\"guesses\")).orderBy(desc(\"guesses\")).limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 442s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 5\n",
    "Find the language with the second highest guessed percentage in Switzerland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 747.340087890625,
      "end_time": 1573678219912.345
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|  guess|guesses|\n",
      "+-------+-------+\n",
      "|Russian|    435|\n",
      "|Italian|    432|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.filter(dataset.country == 'CH').select(\"guess\").groupBy(\"guess\").agg(count(\"guess\").alias(\"guesses\")).orderBy(desc(\"guesses\")).limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 198s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6\n",
    "On which day was any sample played the most ever? Hint: you might need to import `max()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|date      |samples|\n",
      "+----------+-------+\n",
      "|2013-09-04|799435 |\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "\n",
    "dataset.select(\"date\", \"sample\").groupBy(\"date\").agg(count(\"sample\").alias(\"samples\")).orderBy(desc(\"samples\")).limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 157s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>2. Spark SQL</center>\n",
    "\n",
    "Now, for the second weekly quiz, write Spark SQL queries for the same questions as earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sparksql-magic --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparksql_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 15326.347900390625,
      "end_time": 1573674838228.037
     }
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/20 16:37:53 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    }
   ],
   "source": [
    "path = \"confusion-2014-03-02/confusion-part.json\"\n",
    "dataset = spark.read.json(path).cache()\n",
    "dataset.createOrReplaceTempView(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 19343.071044921875,
      "end_time": 1573674865742.795
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">choices</td><td style=\"font-weight: bold\">country</td><td style=\"font-weight: bold\">date</td><td style=\"font-weight: bold\">guess</td><td style=\"font-weight: bold\">sample</td><td style=\"font-weight: bold\">target</td></tr><tr><td>[&#x27;Maori&#x27;, &#x27;Mandarin&#x27;, &#x27;Norwegian&#x27;, &#x27;Tongan&#x27;]</td><td>AU</td><td>2013-08-19</td><td>Norwegian</td><td>48f9c924e0d98c959d8a6f1862b3ce9a</td><td>Norwegian</td></tr><tr><td>[&#x27;Danish&#x27;, &#x27;Dinka&#x27;, &#x27;Khmer&#x27;, &#x27;Lao&#x27;]</td><td>AU</td><td>2013-08-19</td><td>Dinka</td><td>af5e8f27cef9e689a070b8814dcc02c3</td><td>Dinka</td></tr><tr><td>[&#x27;German&#x27;, &#x27;Hungarian&#x27;, &#x27;Samoan&#x27;, &#x27;Turkish&#x27;]</td><td>AU</td><td>2013-08-19</td><td>Turkish</td><td>509c36eb58dbce009ccf93f375358d53</td><td>Samoan</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "-- test it out\n",
    "SELECT *\n",
    "FROM dataset\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "Find the number of games where one of the choices is Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 3269.97802734375,
      "end_time": 1573674917442.039
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">count(1)</td></tr><tr><td>164496</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT COUNT(*)\n",
    "FROM dataset\n",
    "WHERE array_contains(dataset.choices, 'Italian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 158s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "Return the number of (distinct) countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 5283.8310546875,
      "end_time": 1573674952324.165
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">count(DISTINCT country)</td></tr><tr><td>188</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT COUNT(DISTINCT(dataset.country))\n",
    "FROM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 42s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "Return the sample IDs (i.e., the \"sample\" field) of the top 2 games played in Switzerland (CH) where the guessed language is correct (equal to the target one) ordered by date (ascending), then by language (descending)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 2259.453857421875,
      "end_time": 1573674971198.841
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">sample</td></tr><tr><td>74b5340a230b1e0c1d45787bc4280b05</td></tr><tr><td>b7df3f9d67cef259fbcaa5abcad9d774</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT dataset.sample\n",
    "FROM dataset\n",
    "WHERE dataset.country == 'CH'\n",
    "AND dataset.target == dataset.guess\n",
    "ORDER BY dataset.date ASC, dataset.target DESC\n",
    "LIMIT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 125s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "Aggregate all games by guess and target language, ignoring games with correct guesses, count the number of guesses for each group and return the pair with the highest count i.e. the most confused pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 3281.450927734375,
      "end_time": 1573675065646.265
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">guess</td><td style=\"font-weight: bold\">target</td><td style=\"font-weight: bold\">guesses</td></tr><tr><td>Mandarin</td><td>Cantonese</td><td>822</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT dataset.guess, dataset.target, COUNT(dataset.guess) AS guesses\n",
    "FROM dataset\n",
    "WHERE dataset.target != dataset.guess\n",
    "GROUP BY dataset.guess, dataset.target\n",
    "ORDER BY guesses DESC\n",
    "LIMIT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 108s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 5\n",
    "Find the language with the second highest guessed percentage in Switzerland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 1265.067138671875,
      "end_time": 1573675200154.991
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">guess</td><td style=\"font-weight: bold\">guesses</td></tr><tr><td>Russian</td><td>435</td></tr><tr><td>Italian</td><td>432</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT dataset.guess, COUNT(dataset.guess) AS guesses\n",
    "FROM dataset\n",
    "WHERE dataset.country == 'CH'\n",
    "GROUP BY dataset.guess\n",
    "ORDER BY guesses DESC\n",
    "LIMIT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 119s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6\n",
    "On which day was any sample played the most ever?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 5276.5859375,
      "end_time": 1573675226440.07
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">date</td><td style=\"font-weight: bold\">samples</td></tr><tr><td>2013-09-04</td><td>799435</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "SELECT dataset.date, COUNT(dataset.sample) AS samples\n",
    "FROM dataset\n",
    "GROUP BY dataset.date\n",
    "ORDER BY samples DESC\n",
    "LIMIT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 71s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
